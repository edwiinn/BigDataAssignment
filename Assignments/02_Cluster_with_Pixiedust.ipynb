{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession.builder.appName(\"CrimeOneYear\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    return spark,sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark,sc = init_spark()\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"dataset_crimes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264807"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(CASE#,StringType,true),StructField(DATE  OF OCCURRENCE,StringType,true),StructField(BLOCK,StringType,true),StructField( IUCR,StringType,true),StructField( PRIMARY DESCRIPTION,StringType,true),StructField( SECONDARY DESCRIPTION,StringType,true),StructField( LOCATION DESCRIPTION,StringType,true),StructField(ARREST,StringType,true),StructField(DOMESTIC,StringType,true),StructField(BEAT,StringType,true),StructField(WARD,StringType,true),StructField(FBI CD,StringType,true),StructField(X COORDINATE,StringType,true),StructField(Y COORDINATE,StringType,true),StructField(LATITUDE,StringType,true),StructField(LONGITUDE,StringType,true),StructField(LOCATION,StringType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"table_crime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select The Table that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTable = spark.sql(\"select `LATITUDE`,`LONGITUDE` from table_crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTable = resTable.select(df.LATITUDE.cast(\"float\"),\n",
    "df.LONGITUDE.cast(\"float\"))\n",
    "resTable = resTable.filter(df.LATITUDE. isNotNull())\n",
    "resTable = resTable.filter(df.LONGITUDE. isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(LATITUDE,FloatType,true),StructField(LONGITUDE,FloatType,true)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resTable.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "| LATITUDE| LONGITUDE|\n",
      "+---------+----------+\n",
      "|41.897896| -87.76074|\n",
      "| 41.85519| -87.62387|\n",
      "|41.798634| -87.60482|\n",
      "|41.780945|-87.621994|\n",
      "|41.965405|-87.736206|\n",
      "|41.850674|-87.735596|\n",
      "| 41.93156|-87.712296|\n",
      "|41.890266| -87.63109|\n",
      "|41.895947| -87.62976|\n",
      "| 41.86338|-87.695816|\n",
      "| 41.86708|   -87.619|\n",
      "|41.792778| -87.59163|\n",
      "|41.769917|-87.663956|\n",
      "| 41.87527| -87.62425|\n",
      "|41.811363|-87.666275|\n",
      "|41.787395| -87.69606|\n",
      "|41.779728|-87.609566|\n",
      "|41.860172| -87.72988|\n",
      "|41.676212| -87.62172|\n",
      "|41.789845|-87.652336|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resTable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assamble Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=[\"LATITUDE\", \"LONGITUDE\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf = vecAssembler.transform(resTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+\n",
      "| LATITUDE| LONGITUDE|            features|\n",
      "+---------+----------+--------------------+\n",
      "|41.897896| -87.76074|[41.8978958129882...|\n",
      "| 41.85519| -87.62387|[41.8551902770996...|\n",
      "|41.798634| -87.60482|[41.7986335754394...|\n",
      "|41.780945|-87.621994|[41.7809448242187...|\n",
      "|41.965405|-87.736206|[41.9654045104980...|\n",
      "|41.850674|-87.735596|[41.8506736755371...|\n",
      "| 41.93156|-87.712296|[41.9315605163574...|\n",
      "|41.890266| -87.63109|[41.8902664184570...|\n",
      "|41.895947| -87.62976|[41.8959465026855...|\n",
      "| 41.86338|-87.695816|[41.8633804321289...|\n",
      "| 41.86708|   -87.619|[41.8670806884765...|\n",
      "|41.792778| -87.59163|[41.7927780151367...|\n",
      "|41.769917|-87.663956|[41.7699165344238...|\n",
      "| 41.87527| -87.62425|[41.8752708435058...|\n",
      "|41.811363|-87.666275|[41.8113632202148...|\n",
      "|41.787395| -87.69606|[41.7873954772949...|\n",
      "|41.779728|-87.609566|[41.7797279357910...|\n",
      "|41.860172| -87.72988|[41.8601722717285...|\n",
      "|41.676212| -87.62172|[41.6762123107910...|\n",
      "|41.789845|-87.652336|[41.7898445129394...|\n",
      "+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit KMeans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=10, seed=1)  # 2 clusters here\n",
    "model = kmeans.fit(newDf.select('features'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Initial Dataframe to Include Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+----------+\n",
      "| LATITUDE| LONGITUDE|            features|prediction|\n",
      "+---------+----------+--------------------+----------+\n",
      "|41.897896| -87.76074|[41.8978958129882...|         6|\n",
      "| 41.85519| -87.62387|[41.8551902770996...|         8|\n",
      "|41.798634| -87.60482|[41.7986335754394...|         2|\n",
      "|41.780945|-87.621994|[41.7809448242187...|         2|\n",
      "|41.965405|-87.736206|[41.9654045104980...|         6|\n",
      "|41.850674|-87.735596|[41.8506736755371...|         0|\n",
      "| 41.93156|-87.712296|[41.9315605163574...|         6|\n",
      "|41.890266| -87.63109|[41.8902664184570...|         8|\n",
      "|41.895947| -87.62976|[41.8959465026855...|         8|\n",
      "| 41.86338|-87.695816|[41.8633804321289...|         0|\n",
      "| 41.86708|   -87.619|[41.8670806884765...|         8|\n",
      "|41.792778| -87.59163|[41.7927780151367...|         2|\n",
      "|41.769917|-87.663956|[41.7699165344238...|         4|\n",
      "| 41.87527| -87.62425|[41.8752708435058...|         8|\n",
      "|41.811363|-87.666275|[41.8113632202148...|         4|\n",
      "|41.787395| -87.69606|[41.7873954772949...|         4|\n",
      "|41.779728|-87.609566|[41.7797279357910...|         2|\n",
      "|41.860172| -87.72988|[41.8601722717285...|         0|\n",
      "|41.676212| -87.62172|[41.6762123107910...|         1|\n",
      "|41.789845|-87.652336|[41.7898445129394...|         2|\n",
      "+---------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed = model.transform(newDf)\n",
    "transformed.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Graph with Pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Only Showing 100 Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "binsize": "10",
      "chartsize": "100",
      "handlerId": "histogram",
      "keyFields": "LONGITUDE,LATITUDE",
      "legend": "false",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA",
      "mpld3": "true",
      "numbins": "12",
      "rendererId": "mapbox",
      "sortby": "Values DESC",
      "stretch": "true",
      "valueFields": "prediction"
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/02_image_1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load map from mapbox to show cluster of 100 crimes using pixiedust choropleth cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pySpark DataFrame for 'file:///Users/User/Downloads/kuliah/big_data/TugasBigData/dataset_crimes.csv'. Please wait...\n",
      "Loading file using 'SparkSession'\n",
      "Successfully created pySpark DataFrame for 'file:///Users/User/Downloads/kuliah/big_data/TugasBigData/dataset_crimes.csv'\n"
     ]
    }
   ],
   "source": [
    "dataset = pixiedust.sampleData('file:///Users/User/Downloads/kuliah/big_data/TugasBigData/dataset_crimes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "mapView",
      "keyFields": "LONGITUDE,LATITUDE",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "pixieapp_metadata": null
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/02_image_2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
